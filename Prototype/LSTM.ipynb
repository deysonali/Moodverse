{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the emotions dataset\n",
    "dataset = pd.read_csv(\"../Datasets/Positive_thoughts/emotion.data\")\n",
    "dataset = pd.concat([dataset[dataset.emotions == \"joy\"], dataset[dataset.emotions == \"sadness\"]])\n",
    "dataset = dataset.drop(dataset.columns[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading reddit dataset\n",
    "r_dataset = pd.read_csv(\"../Datasets/Negative_thoughts/reddit_posts.txt\", sep=\"\\n\", header=None)\n",
    "r_dataset.columns = [\"text\"]\n",
    "r_dataset[\"emotions\"] = [\"sadness\" for i in range(len(r_dataset))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([dataset, r_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6049dc6e48>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEXCAYAAABYsbiOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAV/UlEQVR4nO3df7BfdZ3f8edrifhryy+5pZjghmrqDlJdMYW0bjuOKASxht2KC7Nbsm7GTCu6264zCtvpZAZlRnY7pctU2aJkDY5DpOwPUg1msyhj7TZIAAVBmdziD5IBiQTBliob9t0/vp90v9zcT37cb3K/uTfPx8x3vue8z+ec8/7O3LmvnHM+35tUFZIkTefnxt2AJOnIZUhIkroMCUlSlyEhSeoyJCRJXYaEJKlrwbgbONROPvnkWrx48bjbkKQ55Z577vlRVU1Mrc+7kFi8eDFbt24ddxuSNKck+f50dW83SZK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHXtNySSrE3yRJJvTbPtQ0kqycltPUmuSzKZ5P4kZw2NXZlkW3utHKq/KckDbZ/rkqTVT0qyuY3fnOTEQ/ORJUkH6kCuJD4DLJ9aTHIacB7wg6HyBcCS9loNXN/GngSsAc4BzgbWDP3Svx5439B+e851BXBHVS0B7mjrkqRZtN8v01XVV5MsnmbTtcCHgduGaiuAm2rwPxltSXJCklOBtwCbq2oXQJLNwPIkdwLHVdWWVr8JuAi4vR3rLe2464A7gY8c1Kc7gi2+4ovjbmFe+d7HLxx3C9K8NKNnEklWADuq6ptTNi0EHh1a395q+6pvn6YOcEpVPdaWHwdOmUmvkqSZO+g/y5HkZcDvMbjVNCuqqpJ0/5/VJKsZ3N7iVa961Wy1JUnz3kyuJF4NnA58M8n3gEXAvUn+HrADOG1o7KJW21d90TR1gB+2W1W09yd6DVXVDVW1tKqWTkzs9fepJEkzdNAhUVUPVNXfrarFVbWYwS2is6rqcWADcFmb5bQMeLrdMtoEnJfkxPbA+jxgU9v2TJJlbVbTZfztM44NwJ5ZUCt54bMPSdIsOJApsDcD/xN4bZLtSVbtY/hG4BFgEvgU8H6A9sD6o8Dd7XXVnofYbcyn2z7/i8FDa4CPA29Psg14W1uXJM2iA5nddOl+ti8eWi7g8s64tcDaaepbgTOnqT8JnLu//iRJh4/fuJYkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkrr2GxJJ1iZ5Ism3hmp/kOQ7Se5P8mdJThjadmWSySQPJzl/qL681SaTXDFUPz3JXa3++STHtvqL2/pk2774UH1oSdKBWXAAYz4D/GfgpqHaZuDKqtqd5BrgSuAjSc4ALgFeB7wS+Msk/6Dt8wng7cB24O4kG6rqIeAa4NqqWp/kj4BVwPXt/amqek2SS9q4Xxvt40ran8VXfHHcLcwr3/v4heNuYST7vZKoqq8Cu6bU/qKqdrfVLcCitrwCWF9VP6uq7wKTwNntNVlVj1TVc8B6YEWSAG8Fbm37rwMuGjrWurZ8K3BuGy9JmiWH4pnEbwG3t+WFwKND27a3Wq/+CuDHQ4Gzp/6CY7XtT7fxkqRZMlJIJPl3wG7gc4emnRn3sTrJ1iRbd+7cOc5WJGlemXFIJPlN4J3Ar1dVtfIO4LShYYtarVd/EjghyYIp9Rccq20/vo3fS1XdUFVLq2rpxMTETD+SJGmKGYVEkuXAh4F3VdWzQ5s2AJe0mUmnA0uArwN3A0vaTKZjGTzc3tDC5SvAu9v+K4Hbho61si2/G/jyUBhJkmbBfmc3JbkZeAtwcpLtwBoGs5leDGxuz5K3VNW/qqoHk9wCPMTgNtTlVfV8O84HgE3AMcDaqnqwneIjwPokHwPuA25s9RuBzyaZZPDg/JJD8HklSQdhvyFRVZdOU75xmtqe8VcDV09T3whsnKb+CIPZT1PrPwUu3l9/kqTDx29cS5K6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKlrvyGRZG2SJ5J8a6h2UpLNSba19xNbPUmuSzKZ5P4kZw3ts7KN35Zk5VD9TUkeaPtclyT7OockafYcyJXEZ4DlU2pXAHdU1RLgjrYOcAGwpL1WA9fD4Bc+sAY4BzgbWDP0S/964H1D+y3fzzkkSbNkvyFRVV8Fdk0prwDWteV1wEVD9ZtqYAtwQpJTgfOBzVW1q6qeAjYDy9u246pqS1UVcNOUY013DknSLJnpM4lTquqxtvw4cEpbXgg8OjRue6vtq759mvq+zrGXJKuTbE2ydefOnTP4OJKk6Yz84LpdAdQh6GXG56iqG6pqaVUtnZiYOJytSNJRZaYh8cN2q4j2/kSr7wBOGxq3qNX2VV80TX1f55AkzZKZhsQGYM8MpZXAbUP1y9osp2XA0+2W0SbgvCQntgfW5wGb2rZnkixrs5oum3Ks6c4hSZolC/Y3IMnNwFuAk5NsZzBL6ePALUlWAd8H3tOGbwTeAUwCzwLvBaiqXUk+Ctzdxl1VVXsehr+fwQyqlwK3txf7OIckaZbsNySq6tLOpnOnGVvA5Z3jrAXWTlPfCpw5Tf3J6c4hSZo9fuNaktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqGikkkvzbJA8m+VaSm5O8JMnpSe5KMpnk80mObWNf3NYn2/bFQ8e5stUfTnL+UH15q00muWKUXiVJB2/GIZFkIfDbwNKqOhM4BrgEuAa4tqpeAzwFrGq7rAKeavVr2ziSnNH2ex2wHPhkkmOSHAN8ArgAOAO4tI2VJM2SUW83LQBemmQB8DLgMeCtwK1t+zrgora8oq3Ttp+bJK2+vqp+VlXfBSaBs9trsqoeqarngPVtrCRplsw4JKpqB/AfgB8wCIengXuAH1fV7jZsO7CwLS8EHm377m7jXzFcn7JPry5JmiWj3G46kcG/7E8HXgm8nMHtolmXZHWSrUm27ty5cxwtSNK8NMrtprcB362qnVX118CfAm8GTmi3nwAWATva8g7gNIC2/XjgyeH6lH169b1U1Q1VtbSqlk5MTIzwkSRJw0YJiR8Ay5K8rD1bOBd4CPgK8O42ZiVwW1ve0NZp279cVdXql7TZT6cDS4CvA3cDS9psqWMZPNzeMEK/kqSDtGD/Q6ZXVXcluRW4F9gN3AfcAHwRWJ/kY612Y9vlRuCzSSaBXQx+6VNVDya5hUHA7AYur6rnAZJ8ANjEYObU2qp6cKb9SpIO3oxDAqCq1gBrppQfYTAzaerYnwIXd45zNXD1NPWNwMZRepQkzZzfuJYkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlS10ghkeSEJLcm+U6Sbyf5x0lOSrI5ybb2fmIbmyTXJZlMcn+Ss4aOs7KN35Zk5VD9TUkeaPtclySj9CtJOjijXkn8IfClqvpF4A3At4ErgDuqaglwR1sHuABY0l6rgesBkpwErAHOAc4G1uwJljbmfUP7LR+xX0nSQZhxSCQ5HvhnwI0AVfVcVf0YWAGsa8PWARe15RXATTWwBTghyanA+cDmqtpVVU8Bm4HlbdtxVbWlqgq4aehYkqRZMMqVxOnATuCPk9yX5NNJXg6cUlWPtTGPA6e05YXAo0P7b2+1fdW3T1PfS5LVSbYm2bpz584RPpIkadgoIbEAOAu4vqreCPwf/vbWEgDtCqBGOMcBqaobqmppVS2dmJg43KeTpKPGKCGxHdheVXe19VsZhMYP260i2vsTbfsO4LSh/Re12r7qi6apS5JmyYxDoqoeBx5N8tpWOhd4CNgA7JmhtBK4rS1vAC5rs5yWAU+321KbgPOSnNgeWJ8HbGrbnkmyrM1qumzoWJKkWbBgxP0/CHwuybHAI8B7GQTPLUlWAd8H3tPGbgTeAUwCz7axVNWuJB8F7m7jrqqqXW35/cBngJcCt7eXJGmWjBQSVfUNYOk0m86dZmwBl3eOsxZYO019K3DmKD1KkmbOb1xLkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldI4dEkmOS3JfkC2399CR3JZlM8vkkx7b6i9v6ZNu+eOgYV7b6w0nOH6ovb7XJJFeM2qsk6eAciiuJ3wG+PbR+DXBtVb0GeApY1eqrgKda/do2jiRnAJcArwOWA59swXMM8AngAuAM4NI2VpI0S0YKiSSLgAuBT7f1AG8Fbm1D1gEXteUVbZ22/dw2fgWwvqp+VlXfBSaBs9trsqoeqarngPVtrCRplox6JfGfgA8Df9PWXwH8uKp2t/XtwMK2vBB4FKBtf7qN///1Kfv06ntJsjrJ1iRbd+7cOeJHkiTtMeOQSPJO4ImquucQ9jMjVXVDVS2tqqUTExPjbkeS5o0FI+z7ZuBdSd4BvAQ4DvhD4IQkC9rVwiJgRxu/AzgN2J5kAXA88ORQfY/hfXp1SdIsmPGVRFVdWVWLqmoxgwfPX66qXwe+Ary7DVsJ3NaWN7R12vYvV1W1+iVt9tPpwBLg68DdwJI2W+rYdo4NM+1XknTwRrmS6PkIsD7Jx4D7gBtb/Ubgs0kmgV0MfulTVQ8muQV4CNgNXF5VzwMk+QCwCTgGWFtVDx6GfiVJHYckJKrqTuDOtvwIg5lJU8f8FLi4s//VwNXT1DcCGw9Fj5Kkg+c3riVJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpK4Zh0SS05J8JclDSR5M8jutflKSzUm2tfcTWz1JrksymeT+JGcNHWtlG78tycqh+puSPND2uS5JRvmwkqSDM8qVxG7gQ1V1BrAMuDzJGcAVwB1VtQS4o60DXAAsaa/VwPUwCBVgDXAOcDawZk+wtDHvG9pv+Qj9SpIO0oxDoqoeq6p72/JPgG8DC4EVwLo2bB1wUVteAdxUA1uAE5KcCpwPbK6qXVX1FLAZWN62HVdVW6qqgJuGjiVJmgWH5JlEksXAG4G7gFOq6rG26XHglLa8EHh0aLftrbav+vZp6pKkWTJySCT5eeBPgH9TVc8Mb2tXADXqOQ6gh9VJtibZunPnzsN9Okk6aowUEklexCAgPldVf9rKP2y3imjvT7T6DuC0od0Xtdq+6oumqe+lqm6oqqVVtXRiYmKUjyRJGjLK7KYANwLfrqr/OLRpA7BnhtJK4Lah+mVtltMy4Ol2W2oTcF6SE9sD6/OATW3bM0mWtXNdNnQsSdIsWDDCvm8G/iXwQJJvtNrvAR8HbkmyCvg+8J62bSPwDmASeBZ4L0BV7UryUeDuNu6qqtrVlt8PfAZ4KXB7e0mSZsmMQ6Kqvgb0vrdw7jTjC7i8c6y1wNpp6luBM2faoyRpNH7jWpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldR3xIJFme5OEkk0muGHc/knQ0OaJDIskxwCeAC4AzgEuTnDHeriTp6HFEhwRwNjBZVY9U1XPAemDFmHuSpKPGgnE3sB8LgUeH1rcD50wdlGQ1sLqt/u8kD89Cb0eLk4EfjbuJ/ck14+5AY+DP5qH1C9MVj/SQOCBVdQNww7j7mI+SbK2qpePuQ5rKn83ZcaTfbtoBnDa0vqjVJEmz4EgPibuBJUlOT3IscAmwYcw9SdJR44i+3VRVu5N8ANgEHAOsraoHx9zW0cbbeDpS+bM5C1JV4+5BknSEOtJvN0mSxsiQkCR1GRJ6gST/PIk/F5IAQ0J7+zVgW5LfT/KL425G6klyYpLXj7uP+c4H19pLkuOAS4H3AgX8MXBzVf1krI3pqJfkTuBdDGZm3gM8AfyPqvrdcfY1n3klob1U1TPArQz+VtapwK8A9yb54Fgbk+D49vP5q8BNVXUO8LYx9zSvGRJ6gSTvSvJnwJ3Ai4Czq+oC4A3Ah8bZmwQsSHIq8B7gC+Nu5mhwRH+ZTmPxL4Brq+qrw8WqejbJqjH1JO1xFYMv136tqu5O8veBbWPuaV7zmYT2kuQU4B+11a9X1RPj7EfS+Hi7SS+Q5GLg68DFDC7p70ry7vF2JQ20WXfHJXlRkjuS7EzyG+Puaz7zSkIvkOSbwNv3XD0kmQD+sqreMN7OJEjyjar6pSS/ArwT+F3gq/58Hj5eSWiqn5tye+lJ/DnRkWPPc9QLgf9aVU+Ps5mjgQ+uNdWXkmwCbm7rlwC3j7EfadgXknwH+L/Av25Xuj8dc0/zmrebtJckvwq8ua3+96r683H2Iw1LchLwdFU9n+TlwN+pqsfH3dd8ZUgIgCRfq6pfTvITBt+yztDmvwF2AX9QVZ8cS4MSkORlDJ5DvKqqVidZAry2qvzOxGFiSOiAJHkF8FdV9dpx96KjV5LPM/hzHJdV1ZktNP6qqn5pzK3NWz6Q1AGpqieBt4y7Dx31Xl1Vvw/8NQy+5MkLr3p1iBkSOmBV9di4e9BR77kkL2VwS5QkrwZ+Nt6W5jdnN0maS9YAXwJOS/I5BhMsfnOsHc1zPpOQNKe052PLGNxm2lJVPxpzS/OaISFpTkmyEPgFhu6ETP2DlDp0vN0kac5Icg2D/z3xQQZTs2HwfMKQOEy8kpA0ZyR5GHh9VfmwepY4u0nSXPIIg/8MS7PE202S5pJngW8kuYOhqa9V9dvja2l+MyQkzSUb2kuzxGcSkqQuryQkHfGSPED7lvV0qur1s9jOUcWQkDQXvLO9X97eP9vef4N9hIdG5+0mSXNGkvuq6o1TavdW1Vnj6mm+cwqspLkkSd48tPJP8PfYYeXtJklzySpgbZLjGfztpqeA3xpvS/Obt5skzTktJKiqp8fdy3xnSEiaU5JcCLwOeMmeWlVdNb6O5jfv5UmaM5L8EYM/8PdBBrebLmbwF2F1mHglIWnOSHJ/Vb1+6P3ngdur6p+Ou7f5yisJSXPJT9v7s0leCewGTh1jP/Oes5skzSX/LckJwB8A9zL4It2nxtvS/GZISJpLvgM8X1V/kuQM4Czgz8fc07zm7SZJc8m/r6qfJPll4K3Ap4Hrx9zTvGZISJpLnm/vFwKfqqovAseOsZ95z5CQNJfsSPJfGEyD3Zjkxfh77LByCqykOSPJy4DlwANVtS3JqcA/rKq/GHNr85YhIUnq8jJNktRlSEiSugwJSVKXISFJ6jIkJEld/w9Q+4KK0acJnwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.emotions.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentences = [text.split(\" \") for text in dataset[\"text\"].values.tolist()]\n",
    "labels = dataset[\"emotions\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'joy', 1: 'sadness'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2id = dict()\n",
    "label2id = dict()\n",
    "\n",
    "max_words = 0 # maximum number of words in a sentence\n",
    "\n",
    "# Construction of word2id dict\n",
    "for sentence in input_sentences:\n",
    "    for word in sentence:\n",
    "        # Add words to word2id dict if not exist\n",
    "        if word not in word2id:\n",
    "            word2id[word] = len(word2id)\n",
    "    # If length of the sentence is greater than max_words, update max_words\n",
    "    if len(sentence) > max_words:\n",
    "        max_words = len(sentence)\n",
    "    \n",
    "# Construction of label2id and id2label dicts\n",
    "label2id = {l: i for i, l in enumerate(set(labels))}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/addy/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/addy/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/addy/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/addy/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/addy/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/addy/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/addy/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/addy/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/addy/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/addy/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/addy/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/addy/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (262891, 2125)\n",
      "Shape of Y: (262891, 2)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "# Encode input words and labels\n",
    "X = [[word2id[word] for word in sentence] for sentence in input_sentences]\n",
    "Y = [label2id[label] for label in labels]\n",
    "\n",
    "# Apply Padding to X\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X = pad_sequences(X, max_words)\n",
    "\n",
    "# Convert Y to numpy array\n",
    "Y = keras.utils.to_categorical(Y, num_classes=len(label2id), dtype='float32')\n",
    "\n",
    "# Print shapes\n",
    "print(\"Shape of X: {}\".format(X.shape))\n",
    "print(\"Shape of Y: {}\".format(Y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 2125)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 2125, 100)    6511100     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2125, 100)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 2125, 200)    160800      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 2125, 200)    0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 2125, 1)      201         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 2125)         0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "attention_vec (Activation)      (None, 2125)         0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 200)          0           dropout_2[0][0]                  \n",
      "                                                                 attention_vec[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          20100       dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            202         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 6,692,403\n",
      "Trainable params: 6,692,403\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 100 # The dimension of word embeddings\n",
    "\n",
    "# Define input tensor\n",
    "sequence_input = keras.Input(shape=(max_words,), dtype='int32')\n",
    "\n",
    "# Word embedding layer\n",
    "embedded_inputs =keras.layers.Embedding(len(word2id) + 1,\n",
    "                                        embedding_dim,\n",
    "                                        input_length=max_words)(sequence_input)\n",
    "\n",
    "# Apply dropout to prevent overfitting\n",
    "embedded_inputs = keras.layers.Dropout(0.2)(embedded_inputs)\n",
    "\n",
    "# Apply Bidirectional LSTM over embedded inputs\n",
    "lstm_outs = keras.layers.wrappers.Bidirectional(\n",
    "    keras.layers.LSTM(embedding_dim, return_sequences=True)\n",
    ")(embedded_inputs)\n",
    "\n",
    "# Apply dropout to LSTM outputs to prevent overfitting\n",
    "lstm_outs = keras.layers.Dropout(0.2)(lstm_outs)\n",
    "\n",
    "# Attention Mechanism - Generate attention vectors\n",
    "input_dim = int(lstm_outs.shape[2])\n",
    "permuted_inputs = keras.layers.Permute((2, 1))(lstm_outs)\n",
    "attention_vector = keras.layers.TimeDistributed(keras.layers.Dense(1))(lstm_outs)\n",
    "attention_vector = keras.layers.Reshape((max_words,))(attention_vector)\n",
    "attention_vector = keras.layers.Activation('softmax', name='attention_vec')(attention_vector)\n",
    "attention_output = keras.layers.Dot(axes=1)([lstm_outs, attention_vector])\n",
    "\n",
    "# Last layer: fully connected with softmax activation\n",
    "fc = keras.layers.Dense(embedding_dim, activation='relu')(attention_output)\n",
    "output = keras.layers.Dense(len(label2id), activation='softmax')(fc)\n",
    "\n",
    "# Finally building model\n",
    "model = keras.Model(inputs=[sequence_input], outputs=output)\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer='adam')\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model 10 iterations\n",
    "model.fit(X, Y, epochs=2, batch_size=64, validation_split=0.1, shuffle=True)\n",
    "model.save(\"./msg_flag_epochs=2, batch_size=64, validation_split=0.1,\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
