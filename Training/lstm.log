Using TensorFlow backend.
/home/addy/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/addy/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/addy/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/addy/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/addy/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/addy/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/addy/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/addy/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/addy/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/addy/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/addy/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/addy/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /home/addy/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
2020-01-19 05:33:35.294619: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-01-19 05:33:35.300627: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz
2020-01-19 05:33:35.301399: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5b30a70 executing computations on platform Host. Devices:
2020-01-19 05:33:35.301440: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-01-19 05:33:35.441034: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING:tensorflow:From /home/addy/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

7136 7136
Shape of X: (14272, 5425)
Shape of Y: (14272, 2)
> Summary
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 5425)         0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 5425, 100)    3773300     input_1[0][0]                    
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 5425, 100)    0           embedding_1[0][0]                
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 5425, 200)    160800      dropout_1[0][0]                  
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 5425, 200)    0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
time_distributed_1 (TimeDistrib (None, 5425, 1)      201         dropout_2[0][0]                  
__________________________________________________________________________________________________
reshape_1 (Reshape)             (None, 5425)         0           time_distributed_1[0][0]         
__________________________________________________________________________________________________
attention_vec (Activation)      (None, 5425)         0           reshape_1[0][0]                  
__________________________________________________________________________________________________
dot_1 (Dot)                     (None, 200)          0           dropout_2[0][0]                  
                                                                 attention_vec[0][0]              
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 100)          20100       dot_1[0][0]                      
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 2)            202         dense_2[0][0]                    
==================================================================================================
Total params: 3,954,603
Trainable params: 3,954,603
Non-trainable params: 0
__________________________________________________________________________________________________
Train on 12844 samples, validate on 1428 samples
Epoch 1/2

   64/12844 [..............................] - ETA: 37:45 - loss: 0.6977 - accuracy: 0.3750
  128/12844 [..............................] - ETA: 34:10 - loss: 0.6956 - accuracy: 0.4375
  192/12844 [..............................] - ETA: 33:11 - loss: 0.6910 - accuracy: 0.5052
  256/12844 [..............................] - ETA: 32:43 - loss: 0.6899 - accuracy: 0.5195
  320/12844 [..............................] - ETA: 32:12 - loss: 0.6883 - accuracy: 0.5312
  384/12844 [..............................] - ETA: 31:49 - loss: 0.6825 - accuracy: 0.5547
  448/12844 [>.............................] - ETA: 31:29 - loss: 0.6874 - accuracy: 0.5446
  512/12844 [>.............................] - ETA: 31:07 - loss: 0.6873 - accuracy: 0.5469
  576/12844 [>.............................] - ETA: 30:54 - loss: 0.6880 - accuracy: 0.5469
  640/12844 [>.............................] - ETA: 30:51 - loss: 0.6896 - accuracy: 0.5437
  704/12844 [>.............................] - ETA: 30:54 - loss: 0.6896 - accuracy: 0.5440
  768/12844 [>.............................] - ETA: 30:39 - loss: 0.6888 - accuracy: 0.5469
  832/12844 [>.............................] - ETA: 30:31 - loss: 0.6879 - accuracy: 0.5505
  896/12844 [=>............................] - ETA: 30:16 - loss: 0.6858 - accuracy: 0.5603
  960/12844 [=>............................] - ETA: 30:03 - loss: 0.6853 - accuracy: 0.5625
 1024/12844 [=>............................] - ETA: 29:52 - loss: 0.6864 - accuracy: 0.5576
 1088/12844 [=>............................] - ETA: 29:41 - loss: 0.6883 - accuracy: 0.5496
 1152/12844 [=>............................] - ETA: 29:29 - loss: 0.6878 - accuracy: 0.5521
 1216/12844 [=>............................] - ETA: 29:15 - loss: 0.6873 - accuracy: 0.5543
 1280/12844 [=>............................] - ETA: 29:01 - loss: 0.6872 - accuracy: 0.5547
 1344/12844 [==>...........................] - ETA: 28:49 - loss: 0.6874 - accuracy: 0.5536
 1408/12844 [==>...........................] - ETA: 28:39 - loss: 0.6866 - accuracy: 0.5575
 1472/12844 [==>...........................] - ETA: 28:28 - loss: 0.6865 - accuracy: 0.5577
 1536/12844 [==>...........................] - ETA: 28:16 - loss: 0.6862 - accuracy: 0.5592
 1600/12844 [==>...........................] - ETA: 28:05 - loss: 0.6862 - accuracy: 0.5587
 1664/12844 [==>...........................] - ETA: 27:53 - loss: 0.6862 - accuracy: 0.5589
 1728/12844 [===>..........................] - ETA: 27:41 - loss: 0.6861 - accuracy: 0.5590
 1792/12844 [===>..........................] - ETA: 27:31 - loss: 0.6865 - accuracy: 0.5575
 1856/12844 [===>..........................] - ETA: 27:21 - loss: 0.6867 - accuracy: 0.5566
 1920/12844 [===>..........................] - ETA: 27:11 - loss: 0.6863 - accuracy: 0.5578
 1984/12844 [===>..........................] - ETA: 27:00 - loss: 0.6860 - accuracy: 0.5590
 2048/12844 [===>..........................] - ETA: 26:49 - loss: 0.6857 - accuracy: 0.5601
 2112/12844 [===>..........................] - ETA: 26:38 - loss: 0.6856 - accuracy: 0.5606
 2176/12844 [====>.........................] - ETA: 26:27 - loss: 0.6859 - accuracy: 0.5593
 2240/12844 [====>.........................] - ETA: 26:20 - loss: 0.6858 - accuracy: 0.5598
 2304/12844 [====>.........................] - ETA: 26:11 - loss: 0.6860 - accuracy: 0.5590